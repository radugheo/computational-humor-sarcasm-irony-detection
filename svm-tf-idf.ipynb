{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def parse_csv(file_path):\n",
    "    tweets = []\n",
    "    classes = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header\n",
    "        for row in reader:\n",
    "            tweet, class_ = ','.join(row[:-1]), row[-1]\n",
    "            tweets.append(tweet)\n",
    "            classes.append(class_)\n",
    "    return tweets, classes\n",
    "\n",
    "train_tweets, train_classes = parse_csv('train.csv')\n",
    "test_tweets, test_classes = parse_csv('test.csv')\n",
    "\n",
    "# print (train_tweets[0])\n",
    "# print (train_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer, lemmatizer, and stop words list\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and stem and lemmatize the words\n",
    "    words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing to each tweet\n",
    "train_tweets = [preprocess_text(tweet) for tweet in train_tweets]\n",
    "test_tweets = [preprocess_text(tweet) for tweet in test_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the transform\n",
    "vectorizer = TfidfVectorizer(max_df=0.50, min_df=5)\n",
    "\n",
    "# Tokenize and build vocab\n",
    "vectorizer.fit(train_tweets)\n",
    "\n",
    "# Encode document\n",
    "train_vectors = vectorizer.transform(train_tweets)\n",
    "test_vectors = vectorizer.transform(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "12 fits failed out of a total of 48.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.73412932 0.73408019 0.7361193  0.72110849\n",
      " 0.73409247 0.73410476        nan        nan 0.7091195  0.70913178\n",
      " 0.69516509 0.66352201 0.70910721 0.70915635]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'loss': 'squared_hinge', 'multi_class': 'ovr', 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'multi_class': ['ovr', 'crammer_singer'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "svc = LinearSVC(dual=False, max_iter=3000)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_vectors, train_classes)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7464320866141733\n"
     ]
    }
   ],
   "source": [
    "# Train a LinearSVC model with the best parameters\n",
    "clf = LinearSVC(**best_params, dual=False)\n",
    "clf.fit(train_vectors, train_classes)\n",
    "\n",
    "# Predict the classes of the test vectors\n",
    "test_predictions = clf.predict(test_vectors)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(test_classes, test_predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7464320866141733\n"
     ]
    }
   ],
   "source": [
    "# Train a LinearSVC model with the best parameters\n",
    "clf = LinearSVC(C=0.1, loss='squared_hinge', multi_class='ovr', penalty= 'l1', dual=False)\n",
    "clf.fit(train_vectors, train_classes)\n",
    "\n",
    "# Predict the classes of the test vectors\n",
    "test_predictions = clf.predict(test_vectors)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(test_classes, test_predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "108 fits failed out of a total of 216.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\andi\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.53616352 0.55020391 0.55137087\n",
      " 0.73552968 0.73457154 0.7333923  0.73552968 0.73457154 0.7333923\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.53825177 0.54621167 0.54660476\n",
      " 0.72099794 0.71642836 0.71593701 0.72099794 0.71642836 0.71593701\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55697229 0.55842178 0.55910967 0.73648781 0.73556653 0.73522258\n",
      " 0.73648781 0.73556653 0.73523487 0.53826405 0.54622396 0.54669074\n",
      " 0.72097337 0.71644064 0.71591244 0.72097337 0.71644064 0.71591244]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 0.1, 'clf__dual': False, 'clf__loss': 'squared_hinge', 'clf__multi_class': 'ovr', 'clf__penalty': 'l1', 'tfidf__max_df': 0.5, 'tfidf__min_df': 1}\n",
      "Accuracy: 0.7469242125984252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.25, 0.5, 0.75],\n",
    "    'tfidf__min_df': [1, 5, 10],\n",
    "    'clf__C': [0.1],\n",
    "    'clf__loss': ['hinge', 'squared_hinge'],\n",
    "    'clf__multi_class': ['ovr'],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__dual': [True, False],\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_tweets, train_classes)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n",
    "\n",
    "# Predict the classes of the test vectors\n",
    "test_predictions = grid_search.predict(test_tweets)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(test_classes, test_predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
